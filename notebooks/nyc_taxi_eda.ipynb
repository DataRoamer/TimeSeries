{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Taxi Data - Exploratory Data Analysis\n",
    "\n",
    "Analysis of NYC taxi trip data with 30-minute intervals from July 2014 to January 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join('..', 'src'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from utils.data_loader import load_time_series, validate_time_series, create_time_features\n",
    "from visualization.plots import plot_time_series, plot_decomposition, plot_seasonal_patterns, plot_acf_pacf\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NYC taxi data\n",
    "df = pd.read_csv('../data/raw/nyc_taxi.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.set_index('timestamp')\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"Total days: {(df.index.max() - df.index.min()).days}\")\n",
    "print(f\"Frequency: {pd.infer_freq(df.index)}\")\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data validation\n",
    "validation_results = validate_time_series(df, value_col='value')\n",
    "print(\"Data Validation Results:\")\n",
    "print(\"=\" * 30)\n",
    "for key, value in validation_results.items():\n",
    "    print(f\"{key:20}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Descriptive Statistics:\")\n",
    "print(\"=\" * 25)\n",
    "print(df['value'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time Series Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the entire time series\n",
    "plot_time_series(df, value_col='value', title='NYC Taxi Trips - Complete Series', \n",
    "                figsize=(15, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive plot with Plotly\n",
    "fig = px.line(df.reset_index(), x='timestamp', y='value',\n",
    "              title='NYC Taxi Trips - Interactive View')\n",
    "fig.update_layout(xaxis_title='Date', yaxis_title='Number of Taxi Trips')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom into first week to see daily patterns\n",
    "first_week = df.iloc[:336]  # 7 days * 48 half-hours\n",
    "plot_time_series(first_week, value_col='value', title='NYC Taxi Trips - First Week Detail',\n",
    "                figsize=(15, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Seasonal Patterns Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time features for seasonal analysis\n",
    "df_features = create_time_features(df)\n",
    "print(f\"Features created: {list(df_features.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot seasonal patterns\n",
    "plot_seasonal_patterns(df, value_col='value', freq='all', figsize=(16, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed hourly pattern\n",
    "hourly_avg = df_features.groupby('hour')['value'].agg(['mean', 'std', 'min', 'max'])\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(hourly_avg.index, hourly_avg['mean'], 'o-', linewidth=2, markersize=6, label='Average')\n",
    "plt.fill_between(hourly_avg.index, \n",
    "                hourly_avg['mean'] - hourly_avg['std'],\n",
    "                hourly_avg['mean'] + hourly_avg['std'], \n",
    "                alpha=0.3, label='Â±1 Std Dev')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Number of Taxi Trips')\n",
    "plt.title('NYC Taxi Trips - Hourly Pattern with Variability')\n",
    "plt.xticks(range(0, 24))\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"Peak hours:\")\n",
    "print(hourly_avg['mean'].nlargest(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day of week analysis\n",
    "dow_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "dow_avg = df_features.groupby('day_of_week')['value'].agg(['mean', 'std'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(dow_names, dow_avg['mean'], yerr=dow_avg['std'], \n",
    "               capsize=5, alpha=0.7, color='skyblue', edgecolor='navy')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Average Number of Taxi Trips')\n",
    "plt.title('NYC Taxi Trips - Day of Week Pattern')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, avg in zip(bars, dow_avg['mean']):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 200,\n",
    "             f'{avg:.0f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Time Series Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose with daily seasonality (48 half-hour periods)\n",
    "plot_decomposition(df, value_col='value', period=48, model='additive', figsize=(15, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekly seasonality analysis\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Weekly decomposition (48 * 7 = 336 half-hour periods)\n",
    "weekly_decomp = seasonal_decompose(df['value'], model='additive', period=336)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Plot components\n",
    "weekly_decomp.trend.plot(ax=axes[0,0], title='Weekly Trend')\n",
    "weekly_decomp.seasonal.iloc[:336].plot(ax=axes[0,1], title='Weekly Seasonal Pattern (First Week)')\n",
    "weekly_decomp.resid.plot(ax=axes[1,0], title='Residuals')\n",
    "\n",
    "# Histogram of residuals\n",
    "axes[1,1].hist(weekly_decomp.resid.dropna(), bins=50, alpha=0.7)\n",
    "axes[1,1].set_title('Distribution of Residuals')\n",
    "axes[1,1].set_xlabel('Residual Value')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Autocorrelation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF and PACF plots\n",
    "plot_acf_pacf(df, value_col='value', lags=100, figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Stationarity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import check_stationarity, make_stationary\n",
    "\n",
    "# Check stationarity of original series\n",
    "print(\"Stationarity Test - Original Series:\")\n",
    "print(\"=\" * 40)\n",
    "stationarity_result = check_stationarity(df['value'])\n",
    "for key, value in stationarity_result.items():\n",
    "    print(f\"{key:20}: {value}\")\n",
    "\n",
    "print(f\"\\nIs stationary: {stationarity_result['is_stationary']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try differencing to make stationary\n",
    "df_diff = make_stationary(df, value_col='value', method='diff')\n",
    "\n",
    "print(\"Stationarity Test - After Differencing:\")\n",
    "print(\"=\" * 42)\n",
    "diff_stationarity = check_stationarity(df_diff['value_diff'].dropna())\n",
    "for key, value in diff_stationarity.items():\n",
    "    print(f\"{key:20}: {value}\")\n",
    "\n",
    "print(f\"\\nIs stationary: {diff_stationarity['is_stationary']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize original vs differenced series\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Original series\n",
    "ax1.plot(df.index, df['value'])\n",
    "ax1.set_title('Original Series')\n",
    "ax1.set_ylabel('Number of Trips')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Differenced series\n",
    "ax2.plot(df_diff.index, df_diff['value_diff'])\n",
    "ax2.set_title('Differenced Series (First Difference)')\n",
    "ax2.set_ylabel('Change in Trips')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loader import detect_outliers\n",
    "\n",
    "# Detect outliers using IQR method\n",
    "outliers = detect_outliers(df, value_col='value', method='iqr', threshold=1.5)\n",
    "\n",
    "print(f\"Number of outliers detected: {outliers.sum()}\")\n",
    "print(f\"Percentage of outliers: {(outliers.sum() / len(df)) * 100:.2f}%\")\n",
    "\n",
    "# Show some outlier examples\n",
    "outlier_data = df[outliers]\n",
    "print(f\"\\nTop 10 outlier values:\")\n",
    "print(outlier_data.nlargest(10, 'value'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outliers\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Plot normal points\n",
    "normal_points = df[~outliers]\n",
    "outlier_points = df[outliers]\n",
    "\n",
    "plt.plot(normal_points.index, normal_points['value'], \n",
    "         color='blue', alpha=0.7, label='Normal')\n",
    "plt.scatter(outlier_points.index, outlier_points['value'], \n",
    "           color='red', s=30, alpha=0.8, label='Outliers', zorder=5)\n",
    "\n",
    "plt.title('NYC Taxi Trips with Outliers Highlighted')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Trips')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Insights Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NYC TAXI DATA - KEY INSIGHTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"ð Dataset Overview:\")\n",
    "print(f\"   â¢ Period: {df.index.min().strftime('%Y-%m-%d')} to {df.index.max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"   â¢ Total records: {len(df):,}\")\n",
    "print(f\"   â¢ Frequency: 30-minute intervals\")\n",
    "print(f\"   â¢ Missing values: {df['value'].isnull().sum()}\")\n",
    "\n",
    "print(f\"\\nð Trip Volume:\")\n",
    "print(f\"   â¢ Average trips per 30min: {df['value'].mean():.0f}\")\n",
    "print(f\"   â¢ Peak trips (30min): {df['value'].max():,}\")\n",
    "print(f\"   â¢ Minimum trips (30min): {df['value'].min():,}\")\n",
    "print(f\"   â¢ Total trips in dataset: {df['value'].sum():,}\")\n",
    "\n",
    "print(f\"\\nð Daily Patterns:\")\n",
    "peak_hour = hourly_avg['mean'].idxmax()\n",
    "low_hour = hourly_avg['mean'].idxmin()\n",
    "print(f\"   â¢ Peak hour: {peak_hour}:00 ({hourly_avg['mean'][peak_hour]:.0f} trips/30min avg)\")\n",
    "print(f\"   â¢ Lowest hour: {low_hour}:00 ({hourly_avg['mean'][low_hour]:.0f} trips/30min avg)\")\n",
    "print(f\"   â¢ Rush hour ratio: {hourly_avg['mean'][peak_hour] / hourly_avg['mean'][low_hour]:.1f}x\")\n",
    "\n",
    "print(f\"\\nð Weekly Patterns:\")\n",
    "busiest_day = dow_avg['mean'].idxmax()\n",
    "quietest_day = dow_avg['mean'].idxmin()\n",
    "print(f\"   â¢ Busiest day: {dow_names[busiest_day]} ({dow_avg['mean'][busiest_day]:.0f} avg trips/30min)\")\n",
    "print(f\"   â¢ Quietest day: {dow_names[quietest_day]} ({dow_avg['mean'][quietest_day]:.0f} avg trips/30min)\")\n",
    "print(f\"   â¢ Weekend vs Weekday ratio: {(dow_avg['mean'][5:].mean() / dow_avg['mean'][:5].mean()):.2f}\")\n",
    "\n",
    "print(f\"\\nð Data Quality:\")\n",
    "print(f\"   â¢ Outliers detected: {outliers.sum()} ({(outliers.sum()/len(df)*100):.1f}%)\")\n",
    "print(f\"   â¢ Series is stationary: {stationarity_result['is_stationary']}\")\n",
    "print(f\"   â¢ Strong daily seasonality: Yes (period=48)\")\n",
    "print(f\"   â¢ Strong weekly seasonality: Yes (period=336)\")\n",
    "\n",
    "print(f\"\\nð¡ Modeling Recommendations:\")\n",
    "print(f\"   â¢ Use seasonal models (SARIMA, Exponential Smoothing)\")\n",
    "print(f\"   â¢ Include hourly and daily features for ML models\")\n",
    "print(f\"   â¢ Consider differencing for stationarity\")\n",
    "print(f\"   â¢ Handle outliers with robust methods\")\n",
    "print(f\"   â¢ Cross-validate with time-aware splits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Data Preprocessing**: Clean outliers, handle any missing values\n",
    "2. **Feature Engineering**: Create lag features, rolling statistics, time-based features\n",
    "3. **Model Development**: Try different forecasting approaches (SARIMA, Prophet, ML models)\n",
    "4. **Model Evaluation**: Use appropriate time series validation techniques\n",
    "5. **Deployment**: Create a forecasting pipeline for real-time predictions\n",
    "\n",
    "Continue to the next notebook: `nyc_taxi_forecasting.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}