{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Taxi Data - Forecasting Models\n",
    "\n",
    "Building and comparing different forecasting models for NYC taxi demand prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join('..', 'src'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from utils.data_loader import load_time_series, create_time_features\n",
    "from utils.preprocessing import create_lag_features, create_rolling_features, scale_data\n",
    "from models.forecasting import (\n",
    "    NaiveForecaster, SeasonalNaiveForecaster, ARIMAForecaster, \n",
    "    ExponentialSmoothingForecaster, RandomForestForecaster, \n",
    "    EnsembleForecaster, ModelSelector\n",
    ")\n",
    "from visualization.plots import plot_forecast_comparison, plot_residuals\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NYC taxi data\n",
    "df = pd.read_csv('../data/raw/nyc_taxi.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.set_index('timestamp')\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\nBasic Statistics:\")\n",
    "print(df['value'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time-based features\n",
    "df_features = create_time_features(df)\n",
    "print(f\"Features added: {[col for col in df_features.columns if col != 'value']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add lag and rolling features for ML models\n",
    "df_ml = create_lag_features(df_features, 'value', lags=[1, 2, 3, 24, 48, 168])\n",
    "df_ml = create_rolling_features(df_ml, 'value', windows=[3, 12, 24, 48])\n",
    "\n",
    "print(f\"Total features created: {len(df_ml.columns)}\")\n",
    "print(f\"Feature columns: {list(df_ml.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series split (last 20% for testing)\n",
    "split_ratio = 0.8\n",
    "split_point = int(len(df) * split_ratio)\n",
    "\n",
    "# For basic models (only need target variable)\n",
    "train_data = df['value'][:split_point]\n",
    "test_data = df['value'][split_point:]\n",
    "\n",
    "# For ML models (need features)\n",
    "df_ml_clean = df_ml.dropna()  # Remove rows with NaN from lag features\n",
    "ml_split_point = int(len(df_ml_clean) * split_ratio)\n",
    "\n",
    "train_ml = df_ml_clean[:ml_split_point]\n",
    "test_ml = df_ml_clean[ml_split_point:]\n",
    "\n",
    "print(f\"Training period: {train_data.index[0]} to {train_data.index[-1]}\")\n",
    "print(f\"Test period: {test_data.index[0]} to {test_data.index[-1]}\")\n",
    "print(f\"Training samples: {len(train_data):,}\")\n",
    "print(f\"Test samples: {len(test_data):,}\")\n",
    "print(f\"ML training samples: {len(train_ml):,}\")\n",
    "print(f\"ML test samples: {len(test_ml):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize train/test split\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(train_data.index, train_data.values, label='Training Data', color='blue', alpha=0.7)\n",
    "plt.plot(test_data.index, test_data.values, label='Test Data', color='red', alpha=0.7)\n",
    "plt.axvline(x=train_data.index[-1], color='black', linestyle='--', alpha=0.8, label='Split Point')\n",
    "plt.title('Train/Test Split for NYC Taxi Data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Taxi Trips')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Naive Forecaster (last value)\n",
    "naive_model = NaiveForecaster()\n",
    "naive_model.fit(train_data)\n",
    "naive_forecast = naive_model.predict(len(test_data))\n",
    "\n",
    "naive_mae = mean_absolute_error(test_data, naive_forecast)\n",
    "naive_rmse = np.sqrt(mean_squared_error(test_data, naive_forecast))\n",
    "\n",
    "print(f\"Naive Model - MAE: {naive_mae:.2f}, RMSE: {naive_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Seasonal Naive Forecaster (daily seasonality)\n",
    "seasonal_naive_model = SeasonalNaiveForecaster(season_length=48)  # 48 half-hours = 1 day\n",
    "seasonal_naive_model.fit(train_data)\n",
    "seasonal_naive_forecast = seasonal_naive_model.predict(len(test_data))\n",
    "\n",
    "snaive_mae = mean_absolute_error(test_data, seasonal_naive_forecast)\n",
    "snaive_rmse = np.sqrt(mean_squared_error(test_data, seasonal_naive_forecast))\n",
    "\n",
    "print(f\"Seasonal Naive Model - MAE: {snaive_mae:.2f}, RMSE: {snaive_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Statistical Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 ARIMA Model\n",
    "print(\"Training ARIMA model...\")\n",
    "arima_model = ARIMAForecaster(order=(2, 1, 2))\n",
    "arima_model.fit(train_data)\n",
    "arima_forecast = arima_model.predict(len(test_data))\n",
    "\n",
    "arima_mae = mean_absolute_error(test_data, arima_forecast)\n",
    "arima_rmse = np.sqrt(mean_squared_error(test_data, arima_forecast))\n",
    "\n",
    "print(f\"ARIMA Model - MAE: {arima_mae:.2f}, RMSE: {arima_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Exponential Smoothing\n",
    "print(\"Training Exponential Smoothing model...\")\n",
    "exp_smooth_model = ExponentialSmoothingForecaster(\n",
    "    trend='add', seasonal='add', seasonal_periods=48\n",
    ")\n",
    "exp_smooth_model.fit(train_data)\n",
    "exp_smooth_forecast = exp_smooth_model.predict(len(test_data))\n",
    "\n",
    "exp_mae = mean_absolute_error(test_data, exp_smooth_forecast)\n",
    "exp_rmse = np.sqrt(mean_squared_error(test_data, exp_smooth_forecast))\n",
    "\n",
    "print(f\"Exponential Smoothing Model - MAE: {exp_mae:.2f}, RMSE: {exp_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Random Forest\n",
    "print(\"Training Random Forest model...\")\n",
    "rf_model = RandomForestForecaster(\n",
    "    lags=[1, 2, 3, 24, 48, 168], n_estimators=100\n",
    ")\n",
    "rf_model.fit(train_data)\n",
    "rf_forecast = rf_model.predict(len(test_data))\n",
    "\n",
    "rf_mae = mean_absolute_error(test_data, rf_forecast)\n",
    "rf_rmse = np.sqrt(mean_squared_error(test_data, rf_forecast))\n",
    "\n",
    "print(f\"Random Forest Model - MAE: {rf_mae:.2f}, RMSE: {rf_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Feature-Rich ML Model using XGBoost\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"Training XGBoost model with rich features...\")\n",
    "\n",
    "# Prepare features\n",
    "feature_cols = [col for col in train_ml.columns if col != 'value']\n",
    "X_train = train_ml[feature_cols]\n",
    "y_train = train_ml['value']\n",
    "X_test = test_ml[feature_cols]\n",
    "y_test = test_ml['value']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train XGBoost\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "xgb_forecast = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "xgb_mae = mean_absolute_error(y_test, xgb_forecast)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_forecast))\n",
    "\n",
    "print(f\"XGBoost Model - MAE: {xgb_mae:.2f}, RMSE: {xgb_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble of best performing models\n",
    "print(\"Training Ensemble model...\")\n",
    "\n",
    "# Re-train individual models for ensemble\n",
    "ensemble_arima = ARIMAForecaster(order=(2, 1, 2))\n",
    "ensemble_exp = ExponentialSmoothingForecaster(trend='add', seasonal='add', seasonal_periods=48)\n",
    "ensemble_rf = RandomForestForecaster(lags=[1, 2, 3, 24, 48, 168])\n",
    "\n",
    "# Create ensemble with equal weights\n",
    "ensemble_model = EnsembleForecaster(\n",
    "    models=[ensemble_arima, ensemble_exp, ensemble_rf],\n",
    "    weights=[0.33, 0.33, 0.34]\n",
    ")\n",
    "\n",
    "ensemble_model.fit(train_data)\n",
    "ensemble_forecast = ensemble_model.predict(len(test_data))\n",
    "\n",
    "ensemble_mae = mean_absolute_error(test_data, ensemble_forecast)\n",
    "ensemble_rmse = np.sqrt(mean_squared_error(test_data, ensemble_forecast))\n",
    "\n",
    "print(f\"Ensemble Model - MAE: {ensemble_mae:.2f}, RMSE: {ensemble_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results\n",
    "results = {\n",
    "    'Model': ['Naive', 'Seasonal Naive', 'ARIMA', 'Exp. Smoothing', 'Random Forest', 'XGBoost', 'Ensemble'],\n",
    "    'MAE': [naive_mae, snaive_mae, arima_mae, exp_mae, rf_mae, xgb_mae, ensemble_mae],\n",
    "    'RMSE': [naive_rmse, snaive_rmse, arima_rmse, exp_rmse, rf_rmse, xgb_rmse, ensemble_rmse]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df['MAPE'] = [\n",
    "    np.mean(np.abs((test_data.values - forecast) / test_data.values)) * 100\n",
    "    for forecast in [naive_forecast, seasonal_naive_forecast, arima_forecast, \n",
    "                    exp_smooth_forecast, rf_forecast, xgb_forecast, ensemble_forecast]\n",
    "]\n",
    "\n",
    "# Sort by MAE\n",
    "results_df = results_df.sort_values('MAE')\n",
    "\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "print(results_df.to_string(index=False, float_format='%.2f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# MAE comparison\n",
    "bars1 = ax1.bar(results_df['Model'], results_df['MAE'], color='skyblue', edgecolor='navy')\n",
    "ax1.set_title('Mean Absolute Error (MAE)')\n",
    "ax1.set_ylabel('MAE')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for bar, mae in zip(bars1, results_df['MAE']):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10,\n",
    "             f'{mae:.0f}', ha='center', va='bottom')\n",
    "\n",
    "# RMSE comparison\n",
    "bars2 = ax2.bar(results_df['Model'], results_df['RMSE'], color='lightcoral', edgecolor='darkred')\n",
    "ax2.set_title('Root Mean Square Error (RMSE)')\n",
    "ax2.set_ylabel('RMSE')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, rmse in zip(bars2, results_df['RMSE']):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 15,\n",
    "             f'{rmse:.0f}', ha='center', va='bottom')\n",
    "\n",
    "# MAPE comparison\n",
    "bars3 = ax3.bar(results_df['Model'], results_df['MAPE'], color='lightgreen', edgecolor='darkgreen')\n",
    "ax3.set_title('Mean Absolute Percentage Error (MAPE)')\n",
    "ax3.set_ylabel('MAPE (%)')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, mape in zip(bars3, results_df['MAPE']):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.2,\n",
    "             f'{mape:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Forecast Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forecasts for top performing models\n",
    "top_models = results_df.head(4)\n",
    "\n",
    "forecasts_dict = {\n",
    "    'ARIMA': arima_forecast,\n",
    "    'Exp. Smoothing': exp_smooth_forecast,\n",
    "    'Random Forest': rf_forecast,\n",
    "    'Ensemble': ensemble_forecast\n",
    "}\n",
    "\n",
    "plot_forecast_comparison(\n",
    "    train_data.iloc[-500:],  # Show last 500 points of training\n",
    "    test_data,\n",
    "    forecasts_dict,\n",
    "    figsize=(18, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom into first week of test predictions\n",
    "week_points = 48 * 7  # 7 days * 48 half-hours\n",
    "test_week = test_data.iloc[:week_points]\n",
    "\n",
    "forecasts_week = {\n",
    "    model: forecast[:week_points] \n",
    "    for model, forecast in forecasts_dict.items()\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.plot(test_week.index, test_week.values, 'k-', linewidth=3, label='Actual', alpha=0.8)\n",
    "\n",
    "colors = ['red', 'green', 'orange', 'purple']\n",
    "for i, (model, forecast) in enumerate(forecasts_week.items()):\n",
    "    plt.plot(test_week.index, forecast, '--', color=colors[i], linewidth=2, label=f'{model} Forecast')\n",
    "\n",
    "plt.title('First Week Forecast Comparison - NYC Taxi Demand')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Taxi Trips')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze residuals for best performing model\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "print(f\"Analyzing residuals for best model: {best_model_name}\")\n",
    "\n",
    "if best_model_name == 'ARIMA':\n",
    "    best_forecast = arima_forecast\n",
    "elif best_model_name == 'Exp. Smoothing':\n",
    "    best_forecast = exp_smooth_forecast\n",
    "elif best_model_name == 'Random Forest':\n",
    "    best_forecast = rf_forecast\n",
    "elif best_model_name == 'XGBoost':\n",
    "    best_forecast = xgb_forecast\n",
    "else:\n",
    "    best_forecast = ensemble_forecast\n",
    "\n",
    "plot_residuals(test_data.values, best_forecast, model_name=best_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Feature Importance (for XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for XGBoost model\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_importance.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 15 Feature Importance - XGBoost Model')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(feature_importance.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series cross-validation using ModelSelector\n",
    "print(\"Performing time series cross-validation...\")\n",
    "\n",
    "# Select a subset of models for CV (to save time)\n",
    "cv_models = {\n",
    "    'seasonal_naive': SeasonalNaiveForecaster(season_length=48),\n",
    "    'arima': ARIMAForecaster(order=(2, 1, 2)),\n",
    "    'exp_smoothing': ExponentialSmoothingForecaster(trend='add', seasonal='add', seasonal_periods=48),\n",
    "    'random_forest': RandomForestForecaster(lags=[1, 2, 3, 24, 48])\n",
    "}\n",
    "\n",
    "selector = ModelSelector(models=cv_models)\n",
    "cv_results = selector.cross_validate(\n",
    "    df['value'], n_splits=5, test_size=48*7, metric='mae'  # 1 week test sets\n",
    ")\n",
    "\n",
    "# Summary of CV results\n",
    "cv_summary = cv_results.groupby('model')['score'].agg(['mean', 'std']).round(2)\n",
    "cv_summary = cv_summary.sort_values('mean')\n",
    "\n",
    "print(\"\\nCross-Validation Results (MAE):\")\n",
    "print(\"=\" * 40)\n",
    "print(cv_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV results\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "models = cv_summary.index.tolist()\n",
    "means = cv_summary['mean'].values\n",
    "stds = cv_summary['std'].values\n",
    "\n",
    "plt.bar(models, means, yerr=stds, capsize=5, alpha=0.7, color='lightblue', edgecolor='navy')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Cross-Validation Results - Model Performance')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels\n",
    "for i, (mean, std) in enumerate(zip(means, stds)):\n",
    "    plt.text(i, mean + std + 20, f'{mean:.0f}Â±{std:.0f}', \n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NYC TAXI FORECASTING - FINAL RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"ðŸ† Best Model: {results_df.iloc[0]['Model']}\")\n",
    "print(f\"   â€¢ MAE: {results_df.iloc[0]['MAE']:.2f} trips\")\n",
    "print(f\"   â€¢ RMSE: {results_df.iloc[0]['RMSE']:.2f} trips\")\n",
    "print(f\"   â€¢ MAPE: {results_df.iloc[0]['MAPE']:.1f}%\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Model Rankings by MAE:\")\n",
    "for i, row in results_df.iterrows():\n",
    "    print(f\"   {results_df.index.get_loc(i)+1}. {row['Model']}: {row['MAE']:.2f}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Key Insights:\")\n",
    "baseline_mae = results_df[results_df['Model'] == 'Seasonal Naive']['MAE'].iloc[0]\n",
    "best_mae = results_df.iloc[0]['MAE']\n",
    "improvement = (baseline_mae - best_mae) / baseline_mae * 100\n",
    "\n",
    "print(f\"   â€¢ Best model improves {improvement:.1f}% over seasonal naive baseline\")\n",
    "print(f\"   â€¢ Seasonal patterns are crucial (seasonal naive >> naive)\")\n",
    "print(f\"   â€¢ ML models benefit from rich feature engineering\")\n",
    "print(f\"   â€¢ Ensemble approaches can provide robust predictions\")\n",
    "\n",
    "print(f\"\\nðŸš€ Deployment Recommendations:\")\n",
    "print(f\"   â€¢ Use {results_df.iloc[0]['Model'].lower()} for production forecasting\")\n",
    "print(f\"   â€¢ Implement real-time model retraining (weekly/monthly)\")\n",
    "print(f\"   â€¢ Monitor for concept drift and seasonal changes\")\n",
    "print(f\"   â€¢ Consider external factors (weather, events, holidays)\")\n",
    "print(f\"   â€¢ Implement prediction intervals for uncertainty quantification\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Business Impact:\")\n",
    "avg_trips = df['value'].mean()\n",
    "error_percentage = best_mae / avg_trips * 100\n",
    "print(f\"   â€¢ Average prediction error: Â±{best_mae:.0f} trips ({error_percentage:.1f}%)\")\n",
    "print(f\"   â€¢ Useful for capacity planning and resource allocation\")\n",
    "print(f\"   â€¢ Can optimize driver deployment and reduce wait times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Model Deployment**: Package the best model for production use\n",
    "2. **Real-time Pipeline**: Set up automated data ingestion and prediction\n",
    "3. **Monitoring**: Implement model performance tracking and drift detection\n",
    "4. **Enhancement**: Add external features (weather, events, holidays)\n",
    "5. **Scaling**: Extend to other taxi zones or cities\n",
    "6. **Business Integration**: Connect predictions to operational systems"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}