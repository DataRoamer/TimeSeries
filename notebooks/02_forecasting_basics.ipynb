{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Time Series Forecasting\n",
    "\n",
    "This notebook covers fundamental forecasting techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.exponential_smoothing.ets import ETSModel\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your preprocessed data\n",
    "# df = pd.read_csv('../data/processed/clean_data.csv', parse_dates=['timestamp'], index_col='timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_ts(data, test_size=0.2):\n",
    "    split_point = int(len(data) * (1 - test_size))\n",
    "    train = data[:split_point]\n",
    "    test = data[split_point:]\n",
    "    return train, test\n",
    "\n",
    "# train_data, test_data = train_test_split_ts(df['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Naive Forecast (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_forecast(train_data, steps):\n",
    "    return [train_data.iloc[-1]] * steps\n",
    "\n",
    "def seasonal_naive_forecast(train_data, steps, season_length):\n",
    "    seasonal_values = train_data.iloc[-season_length:]\n",
    "    forecast = []\n",
    "    for i in range(steps):\n",
    "        forecast.append(seasonal_values.iloc[i % season_length])\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_arima(train_data, order=(1, 1, 1)):\n",
    "    model = ARIMA(train_data, order=order)\n",
    "    fitted_model = model.fit()\n",
    "    return fitted_model\n",
    "\n",
    "def forecast_arima(fitted_model, steps):\n",
    "    forecast = fitted_model.forecast(steps=steps)\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_exp_smoothing(train_data, seasonal_periods=24):\n",
    "    model = ExponentialSmoothing(train_data, \n",
    "                                 trend='add', \n",
    "                                 seasonal='add', \n",
    "                                 seasonal_periods=seasonal_periods)\n",
    "    fitted_model = model.fit()\n",
    "    return fitted_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_forecast(actual, predicted):\n",
    "    mae = mean_absolute_error(actual, predicted)\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "    \n",
    "    return {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAPE': mape\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast_comparison(train_data, test_data, forecasts, model_names):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Plot training data\n",
    "    plt.plot(train_data.index, train_data.values, label='Training Data', color='blue')\n",
    "    \n",
    "    # Plot test data\n",
    "    plt.plot(test_data.index, test_data.values, label='Actual', color='black', linewidth=2)\n",
    "    \n",
    "    # Plot forecasts\n",
    "    colors = ['red', 'green', 'orange', 'purple']\n",
    "    for i, (forecast, name) in enumerate(zip(forecasts, model_names)):\n",
    "        plt.plot(test_data.index, forecast, label=f'{name} Forecast', \n",
    "                color=colors[i % len(colors)], linestyle='--')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title('Forecast Comparison')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Value')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}